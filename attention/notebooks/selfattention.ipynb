{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0faca724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 1\n",
    "num_examples = 5\n",
    "d_in = 8\n",
    "d_out = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a363fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input example\n",
    "X = torch.randn([batch_size,num_examples,d_in])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b4eda124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8023,  1.3586, -0.2543, -0.2553, -0.6454,  0.7406,  0.0163,\n",
       "           0.6733],\n",
       "         [ 0.1661,  0.0428,  2.6721, -0.2022,  0.5432,  0.9540, -0.0680,\n",
       "           1.4866],\n",
       "         [ 0.0049,  1.0914,  0.5357,  1.5779,  0.4256, -0.1693,  0.9343,\n",
       "          -0.3938],\n",
       "         [-0.0477, -1.4761, -0.3724, -2.7631, -0.4528,  0.8164,  0.3976,\n",
       "           0.4988],\n",
       "         [ 0.1362, -1.4812, -0.5030,  0.8695,  1.0143, -0.6060,  1.6648,\n",
       "          -0.1551]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181bfd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfattention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,device):\n",
    "       super(selfattention,self).__init__()\n",
    "       self.d_in = d_in\n",
    "       self.d_out = d_out\n",
    "       # Linear has better initialization compared to other ways of implementation I know\n",
    "       self.device = device\n",
    "       self.query = nn.Linear(d_in,d_out,device=device) ## d_in,d_out\n",
    "       self.key = nn.Linear(d_in,d_out,device = device) ## d_in ,d_out\n",
    "       self.value = nn.Linear(d_in,d_out, device = device) ## d_in,d_out\n",
    "       self.softmax = nn.Softmax(dim = 1 )\n",
    "    def forward(self,X):\n",
    "        qx = self.query(X)\n",
    "        kx = self.key(X)\n",
    "        vx = self.value(X)\n",
    "        # K.T\n",
    "        kx = torch.transpose(kx,1,2)\n",
    "        y = qx @ kx\n",
    "        y /= (self.d_out)**0.5\n",
    "        # creating a mask for causal attention\n",
    "        mask = torch.ones(y.shape, device=self.device)\n",
    "        mask = torch.triu(mask,diagonal=1)\n",
    "        mask = mask.bool()\n",
    "        # applying mask\n",
    "        y  = torch.masked_fill(y,mask,-torch.inf)\n",
    "        # applying softmax\n",
    "        y = self.softmax(y)\n",
    "        # y = (QK.T)@ V\n",
    "        y = y @ qx  \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f18049cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "attention_head = selfattention(d_in,d_out,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9287f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector = attention_head(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "700d77e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1069,  0.1238, -0.1181, -0.0028],\n",
      "         [ 0.0635,  0.1817,  0.1037, -0.2806],\n",
      "         [ 0.1578,  0.1338,  0.1367, -0.3292],\n",
      "         [ 0.0933,  0.3457, -0.0870, -0.2294],\n",
      "         [ 0.8883,  0.5244, -0.3898,  0.0803]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb4742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62a661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
